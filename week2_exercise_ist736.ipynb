{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Exercise #2\n",
    "\n",
    "Professor: Bolton\n",
    "Class: IST 736\n",
    "\n",
    "Group Members: ___ \n",
    "\n",
    "\n",
    "\n",
    "## Instructions: \n",
    "\n",
    "This exercise is designed to prep you with skills needed to complete your assignment this week. Complete the following questions and submit a link to your completed notebook file as instructed. You may work in groups.\n",
    "\n",
    "## Schedule:\n",
    "\n",
    "While in groups, please appropriate your time as follows: \n",
    "\n",
    "     - Q & A (20 minutes)\n",
    "     Discuss in your group any lingering questions from the previous week, or discussion any questions / challenges encountered while reviewing this weeks material. Attempt to share and problem solve with your groupmates. Your instructor will drop into break out groups during this time to assist with the discussion and Q&A. Feel free to discussion concepts, coding, assignments, python tools, best practices, packages, debugging strategies, issues, tips, hints, etc. Use this time wisely! Share info and share tips!\n",
    "\n",
    "    - In-Class Exercise (50 minutes)\n",
    "    Complete the questions and exercises found within this notbook file with your group. Each group need to create 1 file but each individual will submit a link to that file within the git classroom. You can also render the notebook and upload copies if you prefer. Be sure to include *ALL GROUP MEMBERS NAMES* in the file at the top.\n",
    "    \n",
    "    The goal of the in-class exercises is to prep you with the concepts and skills needed to successfully complete that corresponding weeks HW assignment. Take full advantage of this time and work together to maximize the learning and understanding. Your professor will stop by all of the groups to help with any questions.\n",
    "    \n",
    "    - Peer Feedback (20 minutes)\n",
    "    Each group will review another groups submission. This feedback should include \n",
    "            -- positive feedback, eg, what was awesome!\n",
    "            -- constructive criticism, eg, how might you improve\n",
    "            -- tips and hints, eg, coding style, other packages, etc\n",
    "    \n",
    "    - Notes:\n",
    "    If you complete this schedule early you are welcome to leave early or feel free to stick around :) \n",
    "    \n",
    "\n",
    "## Resources:\n",
    "\n",
    "Resources to help complete this assignment:\n",
    "\n",
    "    - Check python docs for the corresponding python packages used.\n",
    "    - https://github.com/boltonvandy/IST736repo\n",
    "    \n",
    "\n",
    "## Professor Feedback:\n",
    "\n",
    "Most professor feedback will be provided asynchronously via the git classroom after class. During class your professor will be focused on observing participation of students, facilitating the class, answering questions, and tracking bugs (ugh ... ). It is important to understand this as there will be multiple groups and tasks. Your professor will work to assist as soon as practical if you have questions or encounter obstacles, but please be patient :). \n",
    "\n",
    "If there are any lingering, unsolved questions at the end of class, please document them and include them in the submission. Your professor will address any such questions within the feedback. \n",
    "\n",
    "Your professor will also offer extensive feedback about coding best practices, helpful hints, python tips, useful python packages, resources, and more!\n",
    "\n",
    "## Grading:\n",
    "\n",
    "Grades will be based on participation and effort of all 3 major components: discussion, in-class exercise, and peer feedback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pixiedust in c:\\users\\jerem\\anaconda3\\lib\\site-packages (1.1.19)\n",
      "Requirement already satisfied: astunparse in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (1.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (2.26.0)\n",
      "Requirement already satisfied: geojson in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (2.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (1.3.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (3.2.2)\n",
      "Requirement already satisfied: markdown in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (3.3.4)\n",
      "Requirement already satisfied: colour in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pixiedust) (0.1.5)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from astunparse->pixiedust) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from astunparse->pixiedust) (0.36.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from matplotlib->pixiedust) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from matplotlib->pixiedust) (1.21.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from matplotlib->pixiedust) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from matplotlib->pixiedust) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from matplotlib->pixiedust) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from pandas->pixiedust) (2020.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from requests->pixiedust) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from requests->pixiedust) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from requests->pixiedust) (1.25.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jerem\\anaconda3\\lib\\site-packages (from requests->pixiedust) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\jerem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\jerem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\jerem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\jerem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\jerem\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jerem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.19</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages for data cleaning, \n",
    "# viz and some sentiment analysis for fun :)\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction.\n",
    "\n",
    "Lets load some twitter data. Our goal will be to \"clean\" it up! We will investigate using stemmers and stopwords! The base code for loading is provided below. Feel free to use a different dataset if you prefer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data files to be used. Political Twitter Data.\n",
    "#sourceDir = \"\"\n",
    "tweetsFile = \"ExtractedTweets.csv\"\n",
    "twitterHandles = \"TwitterHandles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "justTweetsDf = pd.read_csv(tweetsFile)\n",
    "justHandlesDf = pd.read_csv(twitterHandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to confirm data loaded correctly\n",
    "justTweetsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42068\n",
      "\n",
      "44392\n",
      "\n",
      "86460\n"
     ]
    }
   ],
   "source": [
    "# Begin to investigate data. Find num of Dem and Rep\n",
    "\n",
    "print(len(justTweetsDf[justTweetsDf['Party']=='Democrat']))\n",
    "print()\n",
    "print(len(justTweetsDf[justTweetsDf['Party']=='Republican']))\n",
    "print()\n",
    "print(len(justTweetsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 4)\n",
      "(40, 4)\n"
     ]
    }
   ],
   "source": [
    "print(justHandlesDf.shape)\n",
    "justHandlesDf = justHandlesDf.drop_duplicates(subset='Handle')\n",
    "print(justHandlesDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Name</th>\n",
       "      <th>Handle</th>\n",
       "      <th>AvatarURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>US Rep. Darren Soto</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/824454906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>Rep. Jacky Rosen</td>\n",
       "      <td>RepJackyRosen</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/837772241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>US Rep. Al Lawson Jr</td>\n",
       "      <td>RepAlLawsonJr</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/818493713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>Adriano Espaillat</td>\n",
       "      <td>RepEspaillat</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/827580972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>Rep. Blunt Rochester</td>\n",
       "      <td>RepBRochester</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/912673706...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party                  Name         Handle  \\\n",
       "0  Democrat   US Rep. Darren Soto  RepDarrenSoto   \n",
       "1  Democrat      Rep. Jacky Rosen  RepJackyRosen   \n",
       "2  Democrat  US Rep. Al Lawson Jr  RepAlLawsonJr   \n",
       "3  Democrat     Adriano Espaillat   RepEspaillat   \n",
       "8  Democrat  Rep. Blunt Rochester  RepBRochester   \n",
       "\n",
       "                                           AvatarURL  \n",
       "0  https://pbs.twimg.com/profile_images/824454906...  \n",
       "1  https://pbs.twimg.com/profile_images/837772241...  \n",
       "2  https://pbs.twimg.com/profile_images/818493713...  \n",
       "3  https://pbs.twimg.com/profile_images/827580972...  \n",
       "8  https://pbs.twimg.com/profile_images/912673706...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justHandlesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf = justTweetsDf.merge(copy=True, right=justHandlesDf, on='Handle', how='left')\n",
    "tweetsDf = tweetsDf.drop(columns=['Party_y','AvatarURL'])\n",
    "tweetsDf = tweetsDf.rename(columns={'Party_x':'Party'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweetsDf['Handle'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean some of the text data. EG get rid of \"RT\"\n",
    "\n",
    "tweetsDf['IsRetweet'] = tweetsDf['Tweet'].str.startswith('RT')\n",
    "tweetsDf['Tweet'] = tweetsDf['Tweet'].str.replace('RT ', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    86460.000000\n",
       "mean        17.823225\n",
       "std          4.253023\n",
       "min          1.000000\n",
       "25%         16.000000\n",
       "50%         19.000000\n",
       "75%         21.000000\n",
       "max         31.000000\n",
       "Name: WordCount, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quartile Analysis on wordcount\n",
    "\n",
    "tweetsDf['WordCount'] = tweetsDf['Tweet'].str.count(\"\\S\\s+\\S\")+1\n",
    "tweetsDf['WordCount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the Houseâ€¦ https://t.co/n3tggDLU1L\n",
      "17\n",
      "18.045878102120376\n",
      "17.612227428365472\n",
      "42068\n",
      "44392\n"
     ]
    }
   ],
   "source": [
    "# More EDA!! Peak at data and compute mean word counts \n",
    "\n",
    "print(tweetsDf['Tweet'][0])\n",
    "print(tweetsDf['WordCount'][0])\n",
    "\n",
    "print(tweetsDf[tweetsDf['Party']=='Democrat']['WordCount'].mean())\n",
    "print(tweetsDf[tweetsDf['Party']=='Republican']['WordCount'].mean())\n",
    "\n",
    "print(len(tweetsDf[tweetsDf['Party']=='Democrat']))\n",
    "print(len(tweetsDf[tweetsDf['Party']=='Republican']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #1\n",
    "\n",
    "Tokenize Tweets using tweet tokenizer. See TweetTokenizer docs for syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tt = TweetTokenizer()\n",
    "\n",
    "# Tokenize your tweets dataframe her and confirm tokenizer worked :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #2\n",
    "\n",
    "Create a wordcloud to identify high frequency words. What did you find? Are there any words that should be added to the stopword list? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a wordcloud to help viz the text data\n",
    "# Great step for textual EDA\n",
    "# Don;t forget to remove stop words!!\n",
    "\n",
    "import wordcloud\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# <insert code here>\n",
    "\n",
    "# Create wordcloud. See wordcloud docs for syntax. \n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "stopWords.append('')\n",
    "\n",
    "# append stopwords to list\n",
    "# create new word cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #3. \n",
    "\n",
    "How many words did you remove in total? What was the word count before and after your stopword analyses? Show your code and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #4\n",
    "\n",
    "Why are stemmers used in general? Use snowballstemmer or other to stem words. What notable changes do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemmer and or lemmatizer!!\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# iterate through tweets and combine into a list. Then apply stemmer.\n",
    "# Visualize and or quantify results to confirm stemmer is working as desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #5\n",
    "\n",
    "What words are most frequent for Democrat Tweets? How about Republican Tweets? What is the frequency for the top 5 most frequent words? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<insert code and answer here>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
